{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import norm, genextreme\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from data import get_data, extract_date_data\n",
    "from utils import get_path, load_model_data, month, day_of_week, precip_type\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from tqdm.auto import tqdm\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by loading in the weather features and choosing a (roughly) independent subset of these to use for training our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weather_df = pd.read_csv(get_path('data') / 'weather_data.tsv', sep = '\\t')\n",
    "weather_df['precip_type'] = weather_df['precip_type'].map(precip_type)\n",
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "feat_df = weather_df.copy()[[col for col in list(weather_df.columns) if col not in ['date']]]\n",
    "f = plt.figure(figsize = (13, 10))\n",
    "plt.matshow(feat_df.corr(), fignum = f.number, cmap = 'coolwarm', vmin = -1, vmax = 1)\n",
    "plt.xticks(range(feat_df.shape[1]), feat_df.columns, fontsize=14, rotation=90)\n",
    "plt.yticks(range(feat_df.shape[1]), feat_df.columns, fontsize=14)\n",
    "cb = plt.colorbar()\n",
    "cb.ax.tick_params(labelsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see on the above heatmap, our weather features are highly dependent, so we *do* need to trim these down a bit.\n",
    "\n",
    "We see that the majority of the dependencies cluster in three groups: precipitation, wind speed / gusts, and temperature. We therefore start by only including the average values of these three groups, as we hypothesise that these averages will be more reliable when we fetch forecasts for our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['precip_intensity_avg', 'precip_type', 'wind_speed_avg', 'gust_avg', 'temp_avg', 'humidity']\n",
    "trimmed_feat_df = weather_df.copy()[features]\n",
    "f = plt.figure(figsize = (9, 6))\n",
    "plt.matshow(trimmed_feat_df.corr(), fignum = f.number, cmap = 'coolwarm', vmin = -1, vmax = 1)\n",
    "plt.xticks(range(trimmed_feat_df.shape[1]), trimmed_feat_df.columns, fontsize=14, rotation=90)\n",
    "plt.yticks(range(trimmed_feat_df.shape[1]), trimmed_feat_df.columns, fontsize=14)\n",
    "cb = plt.colorbar()\n",
    "cb.ax.tick_params(labelsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The major dependency remaining is between wind speed average and gust average, so we remove the gust average.\n",
    "\n",
    "This is again because we hypothesise that wind speeds are easier to forecast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['precip_intensity_avg', 'precip_type', 'wind_speed_avg', 'temp_avg', 'humidity']\n",
    "final_feat_df = weather_df.copy()[features]\n",
    "f = plt.figure(figsize = (8, 5))\n",
    "plt.matshow(final_feat_df.corr(), fignum = f.number, cmap = 'coolwarm', vmin = -1, vmax = 1)\n",
    "plt.xticks(range(final_feat_df.shape[1]), final_feat_df.columns, fontsize=14, rotation=90)\n",
    "plt.yticks(range(final_feat_df.shape[1]), final_feat_df.columns, fontsize=14)\n",
    "cb = plt.colorbar()\n",
    "cb.ax.tick_params(labelsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks good! We'll also be using some date-related features: `month`, `day_of_month` and `day_of_week`.\n",
    "\n",
    "Let's load in our training dataset with all these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X, y = get_data(include_date = True)\n",
    "df = X.copy()\n",
    "X.drop(columns = ['date'], inplace = True)\n",
    "df['total'] = y.copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of target labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def earlier_than(date1: str, date2: str):\n",
    "    from datetime import datetime\n",
    "    date1, date2 = datetime.strptime(date1, '%Y-%m-%d'), datetime.strptime(date2, '%Y-%m-%d')\n",
    "    return date1 < date2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've chosen our features, let's have a look at what we're trying to predict.\n",
    "\n",
    "Here's a plot of the reported total demand for a Bristol Soup Run Trust (BSRT) over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xticks = list(range(1, len(df.index), 10))\n",
    "ax = df.total.plot(figsize = (15, 7), title = 'Total BSRT demand over time', \n",
    "                   rot = 45, xticks = xticks, color = 'g')\n",
    "ax.set_xticklabels(df.date[xticks])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also see that these values approximately follow a normal distribution, as can be seen on the following histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idxs = [idx for idx, date in zip(df.index, df.date) if earlier_than(date, '2019-11-04')]\n",
    "X_train, X_val = X.iloc[train_idxs, :], X.iloc[list(set(df.index) - set(train_idxs)), :]\n",
    "y_train, y_val = y[train_idxs], y[list(set(df.index) - set(train_idxs))]\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,7))\n",
    "\n",
    "plt.hist(y_train, bins='auto', alpha=0.4, density = True, color='magenta', \n",
    "         label = 'Training set')\n",
    "plt.hist(y_val, bins='auto', alpha=0.4, density = True, color='green', \n",
    "         label = 'Validation set')\n",
    "\n",
    "plt.title('Comparison of BSRT demand distributions of training- and validation set', fontsize = 15)\n",
    "plt.xlabel('Total demand')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend(fontsize = 12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fitted a wide variety of models to the data, and we found that forest-based estimators performed the best in terms of mean absolute error (MAE). Further, we refined this by choosing a forest of `ExtraTrees`, which also performs the splittings in the individual trees at random, reducing variance.\n",
    "\n",
    "We performed a Bayesian hyperparameter search for 150 iterations over all the parameters in the forest, and found that the only parameter that resulted in better performance over the default values were the number of trees, which we increased from 100 to 3000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model_data()['model']\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also wanted to have an idea of the uncertainty coupled with the predictions. We therefore wanted to estimate the variance of the predictions, to approximate both the sample noise and the noise within the trees themselves. A common way of doing this is by trainin the same forest on *bootstrapped samples*, which are datasets that are sampled from our original dataset with replacement, simulating \"random datasets\".\n",
    "\n",
    "The problem with this is inference time: if we're using, say, 1000 bootstrapped datasets, then we need to apply each of our 3000 trees a thousand times every time we want to make a prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A solution to this problem was found in the 2014 paper `Confidence intervals for random forests: The jackknife and the infinitesimal jackknife` by Wager, Hastie and Efron. They found a way to estimate the variance by *only using the trees once*.\n",
    "\n",
    "For this to work we need to have trained our trees on bootstrapped samples, which reduced the performance of the model by a tiny bit (~1 MAE), but we are willing to sacrifice this small amount of performance to reduce the prediction time by a factor of 1000. We've implemented their method into the class `pExtraTreesRegressor`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With their estimate of variance, we can then proceed to compute the standard error of the predictions. We're fortunate that our target values are normally distributed, which allows us to compute the standard prediction error as follows:\n",
    "\n",
    "$$ \\textsf{SE} = \\textsf{Var}_b[\\mathcal T_b(x)]^{1/2}\\sqrt{1 + \\tfrac{1}{B}}, $$\n",
    "\n",
    "where $x$ is a new sample, $\\mathcal T_b(x)$ is the prediction of the $b$'th tree, and $B$ is the amount of trees in the forest. We can therefore compute our $\\alpha$ prediction intervals as\n",
    "\n",
    "$$ \\text{Prediction interval} = \\mathbb{E}_b[\\mathcal T_b(x)] \\pm T_\\alpha^{n-1}\\textsf{SE}, $$\n",
    "\n",
    "where $n$ is the number of training samples, and $T_\\alpha^{n-1}$ is the $\\tfrac{1 + \\alpha}{2}$ percentile of the t-distribution with $n-1$ degrees of freedom.\n",
    "\n",
    "As an example, if $\\alpha = 95\\%$ and we have 138 training samples then $T_\\alpha^{n-1}\\sim 1.98$. In general, as we have more training samples then this will converge to the familiar $1.96$ as the t-distribution converges to the normal distribution.\n",
    "\n",
    "These are all implemented in the `predict` method of the `pExtraTreesRegressor` class, just set `return_intervals = True`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now visualise the performance of the choice of model. We do this by restricting ourselves to a shorter period, and thereby also restricting the number of training samples, and then attempt to predict the following period. We choose here to show the 50%, 80%, 95% and 99% prediction intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [0.5, .8, .95, .99]\n",
    "opacities = np.linspace(0.1, 0.4, len(alphas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viz_model(cutoff_date = '2019-11-04'):\n",
    "    train_idxs = [idx for idx, date in zip(df.index, df.date) if earlier_than(date, cutoff_date)]\n",
    "    \n",
    "    print(f'Number of training samples: {len(train_idxs)}')\n",
    "    print(f'Number of validation samples: {len(df) - len(train_idxs)}')\n",
    "    \n",
    "    X_train, X_val = X.iloc[train_idxs, :], X.iloc[list(set(df.index) - set(train_idxs)), :]\n",
    "    y_train, y_val = y[train_idxs], y[list(set(df.index) - set(train_idxs))]\n",
    "    idxs = sorted(X_val.index)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize = (15, 7))\n",
    "    plt.scatter(df.date[idxs], df.total[idxs], marker = 'x', label = 'True values', color = 'black')\n",
    "    \n",
    "    model = load_model_data()['model'].fit(X_train, y_train)\n",
    "    for idx, alpha in enumerate(alphas):\n",
    "        preds, intervals = model.predict(X_val, return_intervals = True, alpha = alpha)\n",
    "        plt.fill_between(df.date[idxs], intervals[:, 0], intervals[:, 1], \n",
    "                     figure = fig, color = 'purple', alpha = opacities[-(idx + 1)], \n",
    "                         label = f'{round(100 * alpha, 1)}% prediction interval')\n",
    "        \n",
    "        coverage = sum((df.total[idxs] > intervals[:,0]) & (df.total[idxs] < intervals[:,1])) / len(df.total[idxs])\n",
    "        print(f'Coverage for the {100 * alpha:.1f}% prediction interval: {100 * coverage:.1f}%')\n",
    "        \n",
    "    plt.legend(fontsize = 11)\n",
    "    plt.xticks(rotation = 90)\n",
    "    plt.title(f'Predictions - {type(model).__name__}', fontsize = 18)  \n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "viz_model(cutoff_date = '2019-11-04')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the model is not doing a fantastic job, which we attribute to the difference in the training- and validation distributions we saw above.\n",
    "\n",
    "Note also that the actual model is better than this, as it's trained on more data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the model to impute data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, y)\n",
    "y_hat = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,7))\n",
    "\n",
    "plt.hist(y, bins='auto', alpha=0.4, density = True, color='magenta', \n",
    "         label = 'True values')\n",
    "plt.hist(y_hat, bins='auto', alpha=0.4, density = True, color='green', \n",
    "         label = 'Predicted values')\n",
    "\n",
    "plt.title('Comparison of BSRT demand distributions of true and predicted values', fontsize = 15)\n",
    "plt.xlabel('Total demand')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend(fontsize = 12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(zip(model.feature_importances_, X.columns), reverse = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the (fully trained) model to impute all the missing values in our data set.\n",
    "\n",
    "We have weather data for all the dates in `weather_df`, so we just need to extract the date features and merge them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dates = weather_df['date'].map(lambda x: datetime.strptime(x, '%Y-%m-%d'))\n",
    "date_df = extract_date_data(dates)\n",
    "date_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "feat_df = pd.concat([date_df, weather_df[['date'] + features]], axis = 1)\n",
    "feat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feat_df['month'] = feat_df['month'].map(month)\n",
    "feat_df['day_of_week'] = feat_df['day_of_week'].map(day_of_week)\n",
    "feat_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next load our model and perform all the predictions for the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pred_df = feat_df.copy()\n",
    "for alpha in alphas:\n",
    "    preds, intervals = model.predict(feat_df.drop(columns = ['date']), \n",
    "                                     return_intervals = True, alpha = alpha)\n",
    "    pred_df['prediction'] = preds\n",
    "    pred_df[round(100 * (1 - alpha) / 2, 1)] = intervals[:, 0]\n",
    "    pred_df[round(100 * ((1 - alpha) / 2 + alpha), 1)] = intervals[:, 1]\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using these predictions, let's predict the imputed values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (40, 13))\n",
    "\n",
    "for idx, alpha in enumerate(alphas):\n",
    "    plt.fill_between(pred_df.date, \n",
    "                     pred_df[round(100 * (1 - alpha) / 2, 1)], \n",
    "                     pred_df[round(100 * ((1 - alpha) / 2 + alpha), 1)],\n",
    "                     figure = fig, \n",
    "                     color = 'purple', \n",
    "                     alpha = opacities[-(idx + 1)],\n",
    "                     label = f'{int(round(alpha * 100))}% prediction interval'\n",
    "                     )\n",
    "plt.scatter(df.date, df.total, color = 'green', marker = 'x', label = 'True values')\n",
    "plt.xticks(range(1, len(pred_df.index), 25), \n",
    "           pred_df.date[list(range(1, len(pred_df.index), 25))], \n",
    "           rotation = 45)\n",
    "plt.legend(fontsize = 17)\n",
    "plt.title(f'Imputing total demand with {type(model).__name__}', fontsize = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for alpha in alphas:\n",
    "    upper_val = round(100 * (1 + alpha) / 2, 1)\n",
    "    lower_val = round(100 * (1 - alpha) / 2, 1)\n",
    "\n",
    "    proj_preds = pred_df.copy()[pred_df.date.isin(df.date)]\n",
    "    below_upper = df.total.values <= proj_preds[upper_val].values\n",
    "    above_lower = df.total.values >= proj_preds[lower_val].values\n",
    "    coverage = sum(below_upper & above_lower) / len(df)\n",
    "\n",
    "    err_df = proj_preds.copy()\n",
    "    err_df['total'] = df.total.values\n",
    "    above_upper = err_df[~below_upper]\n",
    "    above_err = max(0, (above_upper.total - above_upper[upper_val]).mean())\n",
    "    below_lower = err_df[~above_lower]\n",
    "    below_err = max(0, (below_lower[lower_val] - below_lower.total).mean())\n",
    "\n",
    "    off_value = (above_err + below_err) / 2\n",
    "\n",
    "    interval_size = (proj_preds[upper_val].values - proj_preds[lower_val].values).mean()\n",
    "\n",
    "    print(f'{coverage * 100:.1f}% of the demand was within the {100 * alpha:.1f}% prediction interval.')\n",
    "    print(f'The values outside the interval were on average {off_value:.2f} off.')\n",
    "    print(f'The average length of the interval is {interval_size:.2f}.\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the intervals capture most of the values, which should also be the case as those are the values that we trained the model on!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = ShuffleSplit(n_splits = 5, test_size = 0.2)\n",
    "pbar = tqdm(ss.split(range(X.shape[0])), desc = 'Evaluating', total = ss.n_splits)\n",
    "\n",
    "maes, covs, offs, lens = np.empty(ss.n_splits), np.empty(ss.n_splits), np.empty(ss.n_splits), np.empty(ss.n_splits)\n",
    "for idx, (train_idxs, test_idxs) in enumerate(pbar):\n",
    "    model.fit(X.iloc[train_idxs, :], y[train_idxs])\n",
    "    preds, intervals = model.predict(X.iloc[test_idxs, :], return_intervals = True, alpha = 0.99)\n",
    "    \n",
    "    below_upper = y[test_idxs] <= intervals[:, 1]\n",
    "    above_lower = y[test_idxs] >= intervals[:, 0]\n",
    "    coverage = np.mean(below_upper & above_lower)\n",
    "\n",
    "    above_err = np.mean(y[test_idxs][~below_upper] - intervals[~below_upper, 1])\n",
    "    below_err = np.mean(intervals[~above_lower, 0] - y[test_idxs][~above_lower])\n",
    "    \n",
    "    covs[idx] = np.mean((y[test_idxs] < intervals[:, 1]) & (y[test_idxs] > intervals[:, 0]))\n",
    "    lens[idx] = np.mean(intervals[:, 1] - intervals[:, 0])\n",
    "    maes[idx] = np.abs(preds - y[test_idxs]).mean()\n",
    "    offs[idx] = (above_err + below_err) / 2\n",
    "    \n",
    "print(f'Mean absolute errors: {maes}')\n",
    "print(f'\\t- Average: {maes.mean()}')\n",
    "print(f'\\t- Standard deviation: {maes.std()}')\n",
    "\n",
    "print(f'\\nLengths: {covs}')\n",
    "print(f'\\t- Average: {covs.mean()}')\n",
    "print(f'\\t- Standard deviation: {covs.std()}')\n",
    "\n",
    "print(f'\\nCoverages: {lens}')\n",
    "print(f'\\t- Average: {lens.mean()}')\n",
    "print(f'\\t- Standard deviation: {lens.std()}')\n",
    "\n",
    "print(f'\\nOff values: {offs}')\n",
    "print(f'\\t- Average: {offs.mean()}')\n",
    "print(f'\\t- Standard deviation: {offs.std()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
